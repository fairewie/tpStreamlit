{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8bqu-La-5EFU"
      },
      "source": [
        "# L'API d'OpenAI - https://platform.openai.com/\n",
        "\n",
        "L’API d'OpenAI permet aux développeurs d'accéder aux modèles de traitement du langage naturel GPT-3 de OpenAI pour diverses applications, allant de la génération de contenu à la création d'applications de chatbot.\n",
        "\n",
        "\n",
        "<img src='https://images.lifestyleasia.com/wp-content/uploads/sites/6/2023/01/30023721/openai-chatgpt-elon-musk-artificial-intelligence.png?tr=w-1200,h-900'>\n",
        "\n",
        "A travers [la plateforme d'OpenAI](https://platform.openai.com/), les développeurs ont accès à :\n",
        "- La page de bienvenue présentant les fonctionnalité principales de l’API.\n",
        "- La page de documentation qui présente les principe technique de fonctionnement de l’API via des tutoriels.\n",
        "La page API reference qui présente les point de terminaison de l’API.\n",
        "- La page Exemple qui présente des cas d’utilisation de l’API.\n",
        "- La page Playground qui permet de tester les modèles de génération de texte."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OHNpLB4ct0z3"
      },
      "source": [
        "\n",
        "# 1. Les modèles GPT\n",
        "Le modèle GPT (Generative Pre-trained Transformer) est un modèle de traitement du langage naturel (NLP) basé sur la famille des transformaters. Il a été développé par OpenAI et a été publié pour la première fois en 2018.\n",
        "\n",
        "Le modèle GPT est un modèle de langage pré-entraîné, ce qui signifie qu'il a été entraîné sur un grand corpus de texte non annoté avant d'être fine-tuné pour des tâches spécifiques. GPT a été entraîné sur un corpus de textes en anglais provenant de sources variées telles que des pages web, des livres et des articles de journaux. Il utilise une architecture transformer, qui utilise des couches d'auto-attention pour encoder la séquence d'entrée.\n",
        "\n",
        "* **GPT-1**, la première version de GPT, a été entraîné sur un corpus de 40 Go de texte.\n",
        "\n",
        "* **GPT-2**, la deuxième version de GPT, a été entraîné sur un corpus de 1,5 To de texte et est devenu célèbre pour sa capacité à générer des textes de qualité proche de celle de l'homme.\n",
        "\n",
        "* **GPT-3**, la troisième version de GPT, est l'un des plus grands modèles de langage pré-entraîné au monde, avec 175 milliards de paramètres, et a démontré une capacité impressionnante à effectuer une large gamme de tâches de NLP sans fine-tuning important.\n",
        "\n",
        "* **GPT-4**, la quatrième itération de la série GPT, représente une avancée significative dans le domaine de l'apprentissage automatique et du traitement du langage naturel avec près de 100 000 milliards de paramètres.\n",
        "\n",
        "**L'importance du `prompt`**\n",
        "\n",
        "Un prompt est un texte court qui est utilisé pour initier une tâche ou une interaction avec un système d'IA (intelligence artificielle). Dans le domaine du traitement du langage naturel (NLP), les prompts sont souvent utilisés pour guider la génération de texte ou pour interroger un système de question-réponse.\n",
        "\n",
        "Par exemple, dans le cadre d'une conversation avec un chatbot, le prompt peut être une question ou une déclaration qui invite le chatbot à fournir une réponse appropriée. Dans le cadre de la génération de texte, le prompt peut être une phrase ou un paragraphe qui sert de point de départ à un modèle de langage pour générer du texte cohérent.\n",
        "\n",
        "Les prompts sont devenus de plus en plus populaires avec l'avènement des GPT (Generative Pre-trained Transformer) qui sont des modèles de NLP pré-entraînés capables de générer du texte de manière autonome. Les utilisateurs peuvent fournir des prompts à ces modèles pour générer une variété de contenus, y compris des histoires, des articles de blog, des poèmes et même du code informatique."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WlRFn2_i5DUy",
        "outputId": "1d83db74-2545-476d-e158-84279cae55d1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting openai==0.28.0\n",
            "  Downloading openai-0.28.0-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: requests>=2.20 in c:\\users\\trist\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai==0.28.0) (2.31.0)\n",
            "Requirement already satisfied: tqdm in c:\\users\\trist\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai==0.28.0) (4.65.0)\n",
            "Collecting aiohttp (from openai==0.28.0)\n",
            "  Downloading aiohttp-3.9.1-cp311-cp311-win_amd64.whl.metadata (7.6 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\trist\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.20->openai==0.28.0) (2.1.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\trist\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.20->openai==0.28.0) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\trist\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.20->openai==0.28.0) (1.26.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\trist\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.20->openai==0.28.0) (2022.9.24)\n",
            "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\trist\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->openai==0.28.0) (23.1.0)\n",
            "Collecting multidict<7.0,>=4.5 (from aiohttp->openai==0.28.0)\n",
            "  Downloading multidict-6.0.4-cp311-cp311-win_amd64.whl (28 kB)\n",
            "Collecting yarl<2.0,>=1.0 (from aiohttp->openai==0.28.0)\n",
            "  Downloading yarl-1.9.4-cp311-cp311-win_amd64.whl.metadata (32 kB)\n",
            "Collecting frozenlist>=1.1.1 (from aiohttp->openai==0.28.0)\n",
            "  Downloading frozenlist-1.4.0-cp311-cp311-win_amd64.whl.metadata (5.3 kB)\n",
            "Collecting aiosignal>=1.1.2 (from aiohttp->openai==0.28.0)\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Requirement already satisfied: colorama in c:\\users\\trist\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tqdm->openai==0.28.0) (0.4.6)\n",
            "Downloading openai-0.28.0-py3-none-any.whl (76 kB)\n",
            "   ---------------------------------------- 0.0/76.5 kB ? eta -:--:--\n",
            "   ---------------------------------------- 76.5/76.5 kB 2.1 MB/s eta 0:00:00\n",
            "Downloading aiohttp-3.9.1-cp311-cp311-win_amd64.whl (364 kB)\n",
            "   ---------------------------------------- 0.0/364.8 kB ? eta -:--:--\n",
            "   --------------------------------- ------ 307.2/364.8 kB 6.3 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 364.8/364.8 kB 4.5 MB/s eta 0:00:00\n",
            "Downloading frozenlist-1.4.0-cp311-cp311-win_amd64.whl (44 kB)\n",
            "   ---------------------------------------- 0.0/44.9 kB ? eta -:--:--\n",
            "   ---------------------------------------- 44.9/44.9 kB 2.2 MB/s eta 0:00:00\n",
            "Downloading yarl-1.9.4-cp311-cp311-win_amd64.whl (76 kB)\n",
            "   ---------------------------------------- 0.0/76.7 kB ? eta -:--:--\n",
            "   ---------------------------------------- 76.7/76.7 kB 2.1 MB/s eta 0:00:00\n",
            "Installing collected packages: multidict, frozenlist, yarl, aiosignal, aiohttp, openai\n",
            "Successfully installed aiohttp-3.9.1 aiosignal-1.3.1 frozenlist-1.4.0 multidict-6.0.4 openai-0.28.0 yarl-1.9.4\n"
          ]
        }
      ],
      "source": [
        "!pip install openai==0.28.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {
        "id": "Yv61WSlB5glS"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['text-search-babbage-doc-001',\n",
              " 'curie-search-query',\n",
              " 'text-davinci-003',\n",
              " 'text-search-babbage-query-001',\n",
              " 'babbage',\n",
              " 'babbage-search-query',\n",
              " 'text-babbage-001',\n",
              " 'text-similarity-davinci-001',\n",
              " 'davinci-similarity',\n",
              " 'code-davinci-edit-001',\n",
              " 'curie-similarity',\n",
              " 'babbage-search-document',\n",
              " 'curie-instruct-beta',\n",
              " 'text-search-ada-doc-001',\n",
              " 'davinci-instruct-beta',\n",
              " 'whisper-1',\n",
              " 'text-similarity-babbage-001',\n",
              " 'text-search-davinci-doc-001',\n",
              " 'gpt-3.5-turbo-16k-0613',\n",
              " 'gpt-3.5-turbo-16k',\n",
              " 'babbage-similarity',\n",
              " 'text-embedding-ada-002',\n",
              " 'davinci-search-query',\n",
              " 'text-similarity-curie-001',\n",
              " 'text-davinci-001',\n",
              " 'text-search-davinci-query-001',\n",
              " 'ada-search-document',\n",
              " 'ada-code-search-code',\n",
              " 'babbage-002',\n",
              " 'davinci-002',\n",
              " 'davinci-search-document',\n",
              " 'curie-search-document',\n",
              " 'gpt-4-0613',\n",
              " 'babbage-code-search-code',\n",
              " 'text-search-ada-query-001',\n",
              " 'code-search-ada-text-001',\n",
              " 'babbage-code-search-text',\n",
              " 'gpt-4-vision-preview',\n",
              " 'code-search-babbage-code-001',\n",
              " 'ada-search-query',\n",
              " 'gpt-3.5-turbo',\n",
              " 'ada-code-search-text',\n",
              " 'tts-1-hd',\n",
              " 'text-search-curie-query-001',\n",
              " 'text-davinci-002',\n",
              " 'text-davinci-edit-001',\n",
              " 'code-search-babbage-text-001',\n",
              " 'ada',\n",
              " 'text-ada-001',\n",
              " 'ada-similarity',\n",
              " 'code-search-ada-code-001',\n",
              " 'text-similarity-ada-001',\n",
              " 'gpt-3.5-turbo-0301',\n",
              " 'gpt-4',\n",
              " 'text-search-curie-doc-001',\n",
              " 'text-curie-001',\n",
              " 'curie',\n",
              " 'tts-1',\n",
              " 'gpt-4-0314',\n",
              " 'davinci',\n",
              " 'gpt-3.5-turbo-1106',\n",
              " 'gpt-3.5-turbo-instruct-0914',\n",
              " 'gpt-4-1106-preview',\n",
              " 'dall-e-2',\n",
              " 'gpt-3.5-turbo-instruct',\n",
              " 'gpt-3.5-turbo-0613',\n",
              " 'tts-1-1106',\n",
              " 'tts-1-hd-1106',\n",
              " 'dall-e-3']"
            ]
          },
          "execution_count": 135,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import openai\n",
        "from dotenv import load_dotenv\n",
        "import os\n",
        "load_dotenv()\n",
        "\n",
        "openai.api_key = os.getenv(\"API_KEY\")\n",
        "\n",
        "[model['id'] for model in openai.Model().list()[\"data\"]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Gtc2UG3j5h5B"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<OpenAIObject list at 0x198fc95b170> JSON: {\n",
              "  \"object\": \"list\",\n",
              "  \"data\": [\n",
              "    {\n",
              "      \"id\": \"text-search-babbage-doc-001\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1651172509,\n",
              "      \"owned_by\": \"openai-dev\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"curie-search-query\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1651172509,\n",
              "      \"owned_by\": \"openai-dev\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"text-davinci-003\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1669599635,\n",
              "      \"owned_by\": \"openai-internal\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"text-search-babbage-query-001\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1651172509,\n",
              "      \"owned_by\": \"openai-dev\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"babbage\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1649358449,\n",
              "      \"owned_by\": \"openai\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"babbage-search-query\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1651172509,\n",
              "      \"owned_by\": \"openai-dev\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"text-babbage-001\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1649364043,\n",
              "      \"owned_by\": \"openai\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"text-similarity-davinci-001\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1651172505,\n",
              "      \"owned_by\": \"openai-dev\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"davinci-similarity\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1651172509,\n",
              "      \"owned_by\": \"openai-dev\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"code-davinci-edit-001\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1649880484,\n",
              "      \"owned_by\": \"openai\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"curie-similarity\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1651172510,\n",
              "      \"owned_by\": \"openai-dev\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"babbage-search-document\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1651172510,\n",
              "      \"owned_by\": \"openai-dev\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"curie-instruct-beta\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1649364042,\n",
              "      \"owned_by\": \"openai\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"text-search-ada-doc-001\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1651172507,\n",
              "      \"owned_by\": \"openai-dev\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"davinci-instruct-beta\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1649364042,\n",
              "      \"owned_by\": \"openai\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"whisper-1\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1677532384,\n",
              "      \"owned_by\": \"openai-internal\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"text-similarity-babbage-001\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1651172505,\n",
              "      \"owned_by\": \"openai-dev\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"text-search-davinci-doc-001\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1651172505,\n",
              "      \"owned_by\": \"openai-dev\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"gpt-3.5-turbo-16k-0613\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1685474247,\n",
              "      \"owned_by\": \"openai\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"gpt-3.5-turbo-16k\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1683758102,\n",
              "      \"owned_by\": \"openai-internal\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"babbage-similarity\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1651172505,\n",
              "      \"owned_by\": \"openai-dev\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"text-embedding-ada-002\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1671217299,\n",
              "      \"owned_by\": \"openai-internal\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"davinci-search-query\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1651172505,\n",
              "      \"owned_by\": \"openai-dev\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"text-similarity-curie-001\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1651172507,\n",
              "      \"owned_by\": \"openai-dev\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"text-davinci-001\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1649364042,\n",
              "      \"owned_by\": \"openai\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"text-search-davinci-query-001\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1651172505,\n",
              "      \"owned_by\": \"openai-dev\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"ada-search-document\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1651172507,\n",
              "      \"owned_by\": \"openai-dev\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"ada-code-search-code\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1651172505,\n",
              "      \"owned_by\": \"openai-dev\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"babbage-002\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1692634615,\n",
              "      \"owned_by\": \"system\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"davinci-002\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1692634301,\n",
              "      \"owned_by\": \"system\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"davinci-search-document\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1651172509,\n",
              "      \"owned_by\": \"openai-dev\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"curie-search-document\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1651172508,\n",
              "      \"owned_by\": \"openai-dev\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"gpt-4-0613\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1686588896,\n",
              "      \"owned_by\": \"openai\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"babbage-code-search-code\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1651172509,\n",
              "      \"owned_by\": \"openai-dev\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"text-search-ada-query-001\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1651172505,\n",
              "      \"owned_by\": \"openai-dev\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"code-search-ada-text-001\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1651172507,\n",
              "      \"owned_by\": \"openai-dev\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"babbage-code-search-text\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1651172509,\n",
              "      \"owned_by\": \"openai-dev\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"gpt-4-vision-preview\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1698894917,\n",
              "      \"owned_by\": \"system\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"code-search-babbage-code-001\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1651172507,\n",
              "      \"owned_by\": \"openai-dev\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"ada-search-query\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1651172505,\n",
              "      \"owned_by\": \"openai-dev\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"gpt-3.5-turbo\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1677610602,\n",
              "      \"owned_by\": \"openai\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"ada-code-search-text\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1651172510,\n",
              "      \"owned_by\": \"openai-dev\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"tts-1-hd\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1699046015,\n",
              "      \"owned_by\": \"system\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"text-search-curie-query-001\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1651172509,\n",
              "      \"owned_by\": \"openai-dev\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"text-davinci-002\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1649880484,\n",
              "      \"owned_by\": \"openai\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"text-davinci-edit-001\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1649809179,\n",
              "      \"owned_by\": \"openai\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"code-search-babbage-text-001\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1651172507,\n",
              "      \"owned_by\": \"openai-dev\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"ada\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1649357491,\n",
              "      \"owned_by\": \"openai\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"text-ada-001\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1649364042,\n",
              "      \"owned_by\": \"openai\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"ada-similarity\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1651172507,\n",
              "      \"owned_by\": \"openai-dev\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"code-search-ada-code-001\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1651172507,\n",
              "      \"owned_by\": \"openai-dev\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"text-similarity-ada-001\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1651172505,\n",
              "      \"owned_by\": \"openai-dev\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"gpt-3.5-turbo-0301\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1677649963,\n",
              "      \"owned_by\": \"openai\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"gpt-4\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1687882411,\n",
              "      \"owned_by\": \"openai\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"text-search-curie-doc-001\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1651172509,\n",
              "      \"owned_by\": \"openai-dev\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"text-curie-001\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1649364043,\n",
              "      \"owned_by\": \"openai\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"curie\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1649359874,\n",
              "      \"owned_by\": \"openai\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"tts-1\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1681940951,\n",
              "      \"owned_by\": \"openai-internal\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"gpt-4-0314\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1687882410,\n",
              "      \"owned_by\": \"openai\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"davinci\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1649359874,\n",
              "      \"owned_by\": \"openai\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"gpt-3.5-turbo-1106\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1698959748,\n",
              "      \"owned_by\": \"system\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"gpt-3.5-turbo-instruct-0914\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1694122472,\n",
              "      \"owned_by\": \"system\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"gpt-4-1106-preview\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1698957206,\n",
              "      \"owned_by\": \"system\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"dall-e-2\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1698798177,\n",
              "      \"owned_by\": \"system\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"gpt-3.5-turbo-instruct\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1692901427,\n",
              "      \"owned_by\": \"system\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"gpt-3.5-turbo-0613\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1686587434,\n",
              "      \"owned_by\": \"openai\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"tts-1-1106\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1699053241,\n",
              "      \"owned_by\": \"system\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"tts-1-hd-1106\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1699053533,\n",
              "      \"owned_by\": \"system\"\n",
              "    },\n",
              "    {\n",
              "      \"id\": \"dall-e-3\",\n",
              "      \"object\": \"model\",\n",
              "      \"created\": 1698785189,\n",
              "      \"owned_by\": \"system\"\n",
              "    }\n",
              "  ]\n",
              "}"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "openai.Model().list()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yHc_aaLSuaxb"
      },
      "source": [
        "## 1.1 Text Completion\n",
        "\n",
        "La complétion de texte est une tâche de NLP qui consiste à prédire la suite d'un texte donné. Par exemple, si nous donnons le texte \"Je suis un étudiant en informatique\", le modèle doit prédire la suite du texte, qui est \"à l'Université de Lomé\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "96Qpkwzv5h2j",
        "outputId": "2939295e-e025-49b0-9e4a-c23e134b38ee"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "' produire des contenus personnalisés (y compris des messages automatiques et des issus de données) et des publicités sur Facebook.\\n\\nLe chatbot de Groupon est inspiré par sense of sauver.verify_mobile_number Message ne demande de renseignements personnels et ne prend que dix minutes pour obtenir le numéro de téléphone à moins d‘une idée que tout moment entre votre nom, date de naissance et actuelle adresse. Voici un exemple de ce que ce pourrait votre message :\\n\\nFacebook est co fut initiellement construit autour des interactions de personnes et de groupe, essentiellement des amis, et n‘a jamais aussi bien développé de soutien de base pour les marques. Pourtant, Facebook est devenu un meilleur moyen que Twitter pour les marques d’atteindre leurs communautés et les clients préférentiels ..\\n\\nChaque entreprise et chaque marque a une identité différente. La marque peut être le nom qu’utilise une entreprise, un personnage dans une campagne promotionnelle et un hashtag'"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Générateur de texte\n",
        "response = openai.Completion.create(\n",
        "    engine=\"davinci\",\n",
        "    prompt=\"Je suis un chatbot conçu pour\",\n",
        "    temperature=1,\n",
        "    max_tokens=300)\n",
        "\n",
        "response.choices[0].text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "-AfuaAez5hzj",
        "outputId": "e37f175a-678f-4ba4-c02d-e102dd2da750"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "' Quels salles avez-vous disponibles?\\n2. ¿Qué habitaciones tienes disponibles?\\n3. どの部屋が利用可能ですか？'"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Traduction avec ChatGPT\n",
        "response = openai.Completion.create(\n",
        "  model=\"text-davinci-003\",\n",
        "  prompt=\"Translate this into 1. French, 2. Spanish and 3. Japanese:\\n\\nWhat rooms do you have available?\\n\\n1.\",\n",
        "  temperature=0.3,\n",
        "  max_tokens=100,\n",
        "  top_p=1.0,\n",
        "  frequency_penalty=0.0,\n",
        "  presence_penalty=0.0\n",
        ")\n",
        "response.choices[0].text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X_SkQbWEuhVu"
      },
      "source": [
        "## 1.2 ChatCompletion\n",
        "\n",
        "Les rôles du model GPT-3 dans le chatbot sont les suivants :\n",
        "- **system**: le chatbot, on donne ici le role de system au model GPT-3\n",
        "- **user**: l'utilisateur, on fournira ici la réponse de l'utilisateur\n",
        "- **agent**: l'agent de l'API d'OpenAI, on fournira ici la réponse de l'agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "id": "cnZ3gnNc5hwc",
        "outputId": "d18edb01-47b1-4b6c-930f-fe86da8eaa14"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'- Actualité : Economie La France encore championne d\\'Europe des dépenses de protection sociale en 2022 \\n - Actualité : Tentez de gagner un cadeau France Bleu en trouvant le bon score du match Stade Rennais-Villarreal \\n - Actualité : Taxe sur les plateformes d\\'écoute de musique en ligne : \"La France ne sera plus une priorité pour Spotify\", avertit son DG \\n - Actualité : Inflation, climat, croissance : Dans les coulisses de ceux qui prédisent l\\'économie à la Banque de France \\n - Actualité : Air France-KLM vise une marge opérationnelle supérieure à 8% sur la période 2026-2028 \\n - Actualité : Miss France 2024 : Noa Dutitre (Miss Champagne-Ardenne 2023) raconte comment son père, célèbre footballeur, l\\'aide dans son parcours \\n - Actualité : L’invité de la rédaction de France Bleu Lorraine - Christophe Naegelen, député des Vosges \\n - Actualité : La Suède domine l\\'Allemagne et affrontera la France en demi-finales du Mondial \\n'"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import bs4\n",
        "import requests\n",
        "\n",
        "query = input('What do you want to search for ? ')\n",
        "text = requests.get(f'https://www.bing.com/news/search?q={query}').text\n",
        "soup = bs4.BeautifulSoup(text, 'html.parser')\n",
        "\n",
        "actu = ' '.join([\"- Actualité : \" + link.text+ ' \\n'  for link in soup.find_all('a', 'title')])\n",
        "actu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Bonjour tout le monde'"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "' '.join([\"Bonjour\",\"tout\",\"le\",\"monde\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W8ps-yu05htl",
        "outputId": "85c6e32d-caf1-4f68-cae9-d24910fa452e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[\"- Actualité : Economie La France encore championne d'Europe des dépenses de protection sociale en 2022 \",\n",
              " ' - Actualité : Tentez de gagner un cadeau France Bleu en trouvant le bon score du match Stade Rennais-Villarreal ',\n",
              " ' - Actualité : Taxe sur les plateformes d\\'écoute de musique en ligne : \"La France ne sera plus une priorité pour Spotify\", avertit son DG ',\n",
              " \" - Actualité : Inflation, climat, croissance : Dans les coulisses de ceux qui prédisent l'économie à la Banque de France \",\n",
              " ' - Actualité : Air France-KLM vise une marge opérationnelle supérieure à 8% sur la période 2026-2028 ',\n",
              " \" - Actualité : Miss France 2024 : Noa Dutitre (Miss Champagne-Ardenne 2023) raconte comment son père, célèbre footballeur, l'aide dans son parcours \",\n",
              " ' - Actualité : L’invité de la rédaction de France Bleu Lorraine - Christophe Naegelen, député des Vosges ',\n",
              " \" - Actualité : La Suède domine l'Allemagne et affrontera la France en demi-finales du Mondial \",\n",
              " '']"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "actu.split('\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "3OY1YYtx5hpq",
        "outputId": "0929d69d-a6e4-4c65-e68b-4fde866b7304"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<OpenAIObject chat.completion id=chatcmpl-8VdFJY725RQEnnNxhCKtgy65V1llB at 0x198fdeeb0b0> JSON: {\n",
              "  \"id\": \"chatcmpl-8VdFJY725RQEnnNxhCKtgy65V1llB\",\n",
              "  \"object\": \"chat.completion\",\n",
              "  \"created\": 1702549721,\n",
              "  \"model\": \"gpt-3.5-turbo-0613\",\n",
              "  \"choices\": [\n",
              "    {\n",
              "      \"index\": 0,\n",
              "      \"message\": {\n",
              "        \"role\": \"assistant\",\n",
              "        \"content\": \"La France reste championne d'Europe des d\\u00e9penses de protection sociale en 2022. Par contre, Spotify avertit que la France ne sera plus une priorit\\u00e9 apr\\u00e8s l'introduction d'une taxe sur les plateformes d'\\u00e9coute de musique en ligne. En revanche, Air France-KLM vise une marge op\\u00e9rationnelle sup\\u00e9rieure \\u00e0 8% d'ici 2026-2028. Cependant, dans les coulisses de\"\n",
              "      },\n",
              "      \"finish_reason\": \"length\"\n",
              "    }\n",
              "  ],\n",
              "  \"usage\": {\n",
              "    \"prompt_tokens\": 394,\n",
              "    \"completion_tokens\": 100,\n",
              "    \"total_tokens\": 494\n",
              "  },\n",
              "  \"system_fingerprint\": null\n",
              "}"
            ]
          },
          "execution_count": 115,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "reponse = openai.ChatCompletion.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\",\n",
        "         \"content\": f\"Tu es un rédacteur web qui synthétise l'actualité en 50 mots sur la thématique '{query}' Tu fais des liaisons entre les articles avec des mots tel que 'mais', 'donc', 'or', 'par contre', 'en revanche', 'en effet', 'cependant', 'toutefois', 'par ailleurs', 'par contre', 'par contre, 'enfin'\"},\n",
        "        {\"role\": \"user\",\n",
        "         \"content\": \"Voici la liste des actualités à synthétiser :\" + actu},\n",
        "    ],\n",
        "    max_tokens=100,\n",
        "    temperature=0.9,\n",
        ")\n",
        "\n",
        "reponse['choices'][0]['message'][\"content\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i3BjNZnusjGk"
      },
      "source": [
        "# **2. DALL-E et de l'API DALL-E d'OpenAI en Python**\n",
        "\n",
        "<img src='https://images.openai.com/blob/d3b684dc-eb13-4fbd-a77e-0a397e059fef/dall-e-1.jpg?trim=0,0,0,0&width=3200'>\n",
        "\n",
        "Dans ce notebook, nous allons explorer l'utilisation de DALL-E, une puissante modèle de génération d'images développé par OpenAI. DALL-E est capable de générer des images à partir de descriptions textuelles, ou de transformer des images existantes en fonction de certaines spécifications.\n",
        "\n",
        "Nous allons également voir comment utiliser l'API DALL-E d'OpenAI pour intégrer cette technologie dans nos applications Python.\n",
        "\n",
        "\n",
        "## 2.1 Création d'images à partir de texte\n",
        "\n",
        "DALL-E est un modèle de génération d'images qui peut créer des images à partir de descriptions textuelles. Il est capable de générer des images à partir de descriptions textuelles, ou de transformer des images existantes en fonction de certaines spécifications."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "metadata": {
        "id": "cbDmatg_rh1j"
      },
      "outputs": [],
      "source": [
        "# Configurations & Imports\n",
        "from IPython.display import Image\n",
        "import requests\n",
        "\n",
        "# Generate image from text\n",
        "import openai\n",
        "\n",
        "openai.api_key = os.getenv(\"API_KEY\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "5qQM_L-wsK8o"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'https://oaidalleapiprodscus.blob.core.windows.net/private/org-LQTlKf4xJJRjJoDiPvPOzZJD/user-4kxhq9RGmV01JjHdVuqBCwmK/img-uxlOZZSQ9I3lxYtPWA7utTt2.png?st=2023-12-14T08%3A56%3A22Z&se=2023-12-14T10%3A56%3A22Z&sp=r&sv=2021-08-06&sr=b&rscd=inline&rsct=image/png&skoid=6aaadede-4fb3-4698-a8f6-684d7786b067&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2023-12-14T09%3A43%3A08Z&ske=2023-12-15T09%3A43%3A08Z&sks=b&skv=2021-08-06&sig=F1y%2BiBDYwXxb/SdYjrXY54PjXyFSr9kjChhFWe3Vgnc%3D'"
            ]
          },
          "execution_count": 75,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Generate image from text\n",
        "response = openai.Image.create(\n",
        "  prompt=\"final video game boss fight\\n\\n\",\n",
        "  n=1,\n",
        "  size=\"1024x1024\"\n",
        ")\n",
        "image_url = response['data'][0]['url']\n",
        "image_url"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "-8NybqKNsPDC"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Image at 0x198fc8f1c70> JSON: {}"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Show image\n",
        "Image(url=image_url)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jWM0DYmSs5rh"
      },
      "source": [
        "# 2.2 Création d'une variante d'une image\n",
        "\n",
        "DALL-E peut également être utilisé pour créer des variantes d'une image. Pour ce faire, il suffit de télécharger une image et de la soumettre à DALL-E. Le modèle génère alors une variante de l'image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "ETiQT2uwsR0b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Image at 0x198fc979130> JSON: {}"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Download image from url\n",
        "def download_image(url_img, img_name):\n",
        "    img = requests.get(url_img).content\n",
        "    with open(img_name, 'wb') as handler:\n",
        "        handler.write(img)\n",
        "\n",
        "# Download image\n",
        "download_image(image_url, 'img.png')\n",
        "\n",
        "# Show image\n",
        "Image(url='img.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "sqv_Xfb7sbUZ"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Image at 0x198fc97abd0> JSON: {}"
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create image variation\n",
        "response = Image.create_variation(\n",
        "  image=open(\"img.png\", \"rb\"),\n",
        "  n=1,\n",
        "  size=\"1024x1024\"\n",
        ")\n",
        "image_url = response['data'][0]['url']\n",
        "\n",
        "Image(url=image_url)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bVFfxEAXsr-J"
      },
      "source": [
        "## 2.3 Edition d'images à partir de texte et d'un masque\n",
        "\n",
        "DALL-E utilise ces informations pour générer une image éditée qui répond aux spécifications de l'utilisateur. Le modèle combine les informations du texte et du masque pour effectuer les modifications souhaitées sur l'image source.\n",
        "\n",
        "L'édition d'une image peut se faire à partir de la plateforme DALL-E : https://labs.openai.com/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y6GijefWsW1t"
      },
      "outputs": [],
      "source": [
        "# Edit image from text and mask\n",
        "response = openai.Image.create_edit(\n",
        "  image=open(\"img.png\", \"rb\"),\n",
        "  mask=open(\"mask.png\", \"rb\"),\n",
        "  prompt=\"red eyes\",\n",
        "  n=1,\n",
        "  size=\"1024x1024\"\n",
        ")\n",
        "image_url = response['data'][0]['url']\n",
        "\n",
        "Image(url=image_url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "8o2P7bPhwJ-O"
      },
      "outputs": [],
      "source": [
        "from chatgpt import TextProcessor "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "import openai\n",
        "import bs4\n",
        "import requests\n",
        "\n",
        "\n",
        "class TEST:\n",
        "    def __init__(self, text):\n",
        "        self.text = text\n",
        "    \n",
        "    def openai_translate(self, language):\n",
        "        response = openai.Completion.create(\n",
        "        model=\"text-davinci-003\",\n",
        "        prompt=f\"Translate the text after in {language}:\\n\\n{self}\\n\\n1.\",\n",
        "        temperature=0.3,\n",
        "        max_tokens=100,\n",
        "        top_p=1.0,\n",
        "        frequency_penalty=0.0,\n",
        "        presence_penalty=0.0\n",
        "        )\n",
        "        response.choices[0].text\n",
        "        return response.choices[0].text\n",
        "    \n",
        "    def openai_text_summary(self):\n",
        "        reponse = openai.ChatCompletion.create(\n",
        "            model=\"gpt-3.5-turbo\",\n",
        "            messages=[\n",
        "                {\"role\": \"system\",\n",
        "                \"content\": f\"resume moi le texte suivant: '{self}' Tu fais des liaisons entre les articles avec des mots tel que 'mais', 'donc', 'or', 'par contre', 'en revanche', 'en effet', 'cependant', 'toutefois', 'par ailleurs', 'par contre', 'par contre, 'enfin'\"},\n",
        "                {\"role\": \"user\",\n",
        "                \"content\": \"Voici la liste des actualités à synthétiser :\" + actu},\n",
        "            ],\n",
        "            max_tokens=100,\n",
        "            temperature=0.9,\n",
        "        )\n",
        "\n",
        "        return reponse['choices'][0]['message'][\"content\"]\n",
        "    \n",
        "    def openai_text_generator(self):\n",
        "\n",
        "        text = requests.get(f'https://www.bing.com/news/search?q={self}').text\n",
        "        soup = bs4.BeautifulSoup(text, 'html.parser')\n",
        "\n",
        "        actu = ' '.join([\"- Actualité : \" + link.text+ ' \\n'  for link in soup.find_all('a', 'title')])\n",
        "\n",
        "        actu.split('\\n')\n",
        "        reponse = openai.ChatCompletion.create(\n",
        "            model=\"gpt-3.5-turbo\",\n",
        "            messages=[\n",
        "                {\"role\": \"system\",\n",
        "                \"content\": f\"Tu es un rédacteur web qui synthétise l'actualité en 50 mots sur la thématique '{query}' Tu fais des liaisons entre les articles avec des mots tel que 'mais', 'donc', 'or', 'par contre', 'en revanche', 'en effet', 'cependant', 'toutefois', 'par ailleurs', 'par contre', 'par contre, 'enfin'\"},\n",
        "                {\"role\": \"user\",\n",
        "                \"content\": \"Voici la liste des actualités à synthétiser :\" + actu},\n",
        "            ],\n",
        "            max_tokens=100,\n",
        "            temperature=0.9,\n",
        "        )\n",
        "\n",
        "        return reponse\n",
        "\n",
        "\n",
        "    def openai_codex(self):\n",
        "        reponse = openai.ChatCompletion.create(\n",
        "        model=\"gpt-4\",\n",
        "        messages=[\n",
        "            {\"role\": \"assistant\",\n",
        "            \"content\": f\"Corrige le code envoyé\"},\n",
        "            {\"role\": \"user\",\n",
        "            \"content\": \"Voici le code à corriger :\" + self},\n",
        "        ],\n",
        "        max_tokens=200,\n",
        "        temperature=0.9,\n",
        "    )\n",
        "\n",
        "        return reponse\n",
        "\n",
        "    def openai_image(self):\n",
        "        response = openai.Image.create(\n",
        "        prompt=self,\n",
        "        n=1,\n",
        "        size=\"1024x1024\"\n",
        "        )\n",
        "        image_url = response['data'][0]['url']\n",
        "        image_url\n",
        "        return image_url"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "id": "UyGbQs9lwJ7X"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Nous nous appelons Pablo Escobar.\n"
          ]
        }
      ],
      "source": [
        "# use openai_translate to translate text\n",
        "res = TEST.openai_translate(\"los sientos me llamos pablos escobar\", \"french\")\n",
        "print(res)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "G_6XoNbnwJ4w"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "En 2022, la France conserve sa place de championne d'Europe en termes de dépenses de protection sociale. Cependant, certaines conséquences sont à noter. En effet, Spotify, la plateforme d'écoute de musique en ligne, prévoit de ne plus faire de la France une priorité en raison de la taxe imposée sur ces plateformes. De plus, à la Banque de France, des experts tentent de\n"
          ]
        }
      ],
      "source": [
        "resa = TEST.openai_text_summary(\"- Actualité : Economie La France encore championne d'Europe des dépenses de protection sociale en 2022 \")\n",
        "print(resa)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "id": "EzTCBdT1wJ2R"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dans les coulisses de la Banque de France, des experts prédisent l'économie, mais en 2024, les prix vont augmenter dans les transports, l'électricité, les assurances et le tabac. Dans le domaine social, la France est toujours en tête des dépenses en Europe. Pendant ce temps, la Bourse de Paris atteint des records, mais la guerre entre Israël et le Hamas asphyxie l'économie en\n"
          ]
        }
      ],
      "source": [
        "resu = TEST.openai_text_generator(\"economie\")\n",
        "print(resu['choices'][0]['message'][\"content\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {
        "id": "_TaPfYRZwJzk"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Voici le code corrigé :\n",
            "\n",
            "```java\n",
            "int a = 5; \n",
            "int b = 5; //La variable 'e' n'est pas définie. J'ai remplacé 'e' avec '5' pour que le code puisse s'exécuter sans erreurs.\n",
            "int c = a + b; \n",
            "System.out.println(c); //Pour imprimer une variable en java, on utilise 'System.out.println()'\n",
            "```\n"
          ]
        }
      ],
      "source": [
        "resul = TEST.openai_codex(\"int a = 5; int b = e; int c = a + b; print(c);\")\n",
        "print(resul[\"choices\"][0]['message'][\"content\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {
        "id": "fD_r6DHwwJuF"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<img src=\"https://oaidalleapiprodscus.blob.core.windows.net/private/org-LQTlKf4xJJRjJoDiPvPOzZJD/user-4kxhq9RGmV01JjHdVuqBCwmK/img-ucXX9QxANNKN3oWJtteTvc8p.png?st=2023-12-14T09%3A42%3A05Z&se=2023-12-14T11%3A42%3A05Z&sp=r&sv=2021-08-06&sr=b&rscd=inline&rsct=image/png&skoid=6aaadede-4fb3-4698-a8f6-684d7786b067&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2023-12-14T07%3A54%3A14Z&ske=2023-12-15T07%3A54%3A14Z&sks=b&skv=2021-08-06&sig=8hBade4AydvUU9kVkA2jK%2BnKGY9iqWxDH8Ja6MucLe0%3D\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "execution_count": 134,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "image_url = TEST.openai_image(\"guerre de troie\")\n",
        "Image(url=image_url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fT5NJ-0ewJrV"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IUL9Mo50wKyD"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xNCGIDuMwKvu"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lpbSUbDswJo6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ty71uzBd53Ya"
      },
      "source": [
        "___\n",
        "# `Exercice`\n",
        "\n",
        "### 1. Créez une classe **TextProcessor** qui possède les  méthodes suivantes :\n",
        "- `openai_translate` : qui traduit le texte passé en entré\n",
        "- `oepenai_text_sumary` : qui résume le texte passé en entrée\n",
        "- `openai_text_generator` : qui génère du texte en fonction d’une thématique et d’un contenu.\n",
        "- `openai_codex` : qui corrige le code passé en entré.\n",
        "- `openai_image` : qui retourne une image en fonction du prompte passé en argument.\n",
        "\n",
        "\n",
        "### 2. Concevez une page web qui reprend les différentes fonctionnalités créées précédemment sous forme de chatbot, les fonctionnalités s'activent en fonction des codes envoyés dans la conversation :\n",
        "\n",
        "**Fonctionnalités standards** :\n",
        "- `/translate + texte` : Traduit le text envoyé.\n",
        "- `/summary + texte` : Résume le texte envoyé.\n",
        "- `/imagine + prompt` : Génère une image à partir du primpt envoyé.\n",
        "- `/code + text` : Retourne le code corrigé.\n",
        "\n",
        "**Fonctionnalités Scraping** :\n",
        "- `/actu + theme` : Fait un résumé de 5 actualités à partir du theme envoyé.\n",
        "- `/json + url` : Retourne le contenu de l'url envoyé sous forme de json. (Utilisez le site [20minutes](https://www.20minutes.fr) pour faire vos tests).\n",
        "\n",
        "Le chat doit garder l'historique de la conversation.\n",
        "\n",
        "\n",
        "Vous pouvez également vous aider de la documentation : [Streamlit](https://docs.streamlit.io/knowledge-base/tutorials/build-conversational-apps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157
        },
        "id": "aMLIGljREW0i",
        "outputId": "918dc424-fbe0-44d0-9161-e6a03c2d3ad3"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"Recherche-20MinutesRetoursurlapaged'accueil20MinutesMenuRechercheOkActualitéActualitéSociétéMondeFaitsdiversEconomieSantéPolitiqueJusticeFakeOffAUDIENCE«\\xa0T’asquoiàcacher\\xa0?\\xa0»Face-à-facetenduentreMoniqueOlivieretsonfil…états-unisHunterBidendéfielesrépublicainsetdéfendsonpèreRécapBidenrencontredesfamillesd’otagesaméricainsau68ejourduconflitRégionsRégionsParisMarseilleToulouseLilleNantesLyonBordeauxMontpellierArgumentsLesJOcontrairesàlaluttepourleclimat\\xa0?AnneHidalgorépondprocèsEllecroisedansBordeauxl’hommequ’elleaccusedeviolFaitdiversUneballeperduefinitdansletéléviseurd’unlogementenEssonneSportSportFootballBiathlonTennisRugbyBasketHandballCyclismeFormule1FOOTBALLNicolasSarkozyditn’avoireu«\\xa0aucunrôle\\xa0»danslaprolongationdeMbapp…BIATHLONCommesuivrel'étapedelaCoupedumondedeBiathlonàLenzerheideATHLETISMEKevinMayerreporteàmarssatentativedequalificationolympiqueDivertissementDivertissementCultureT'asvu?PeopleWebTélévisionCinémaSérieLivresCapitalePourquoiBourgesest-elledésignéecapitaleeuropéennedelacultureen\\xa0202…01:43REGARDDEPHOTOGRAPHEAïe…«\\xa0Legestepastrèstechnique\\xa0»deJonathanGraditcontreleFCSévill…01:09FILDESSTARSLeprinceWilliametKatherineSchwarzeneggersontdansleFildesStarsPlanètePlanèteÉcologieÉnergieAnimauxMétéoPlantesOcéansDANGERQuelssontlesrisquespourlevillagedeMaurienneaprèsl’éboulementXXL\\xa0…INONDATIONSDenombreuxsecteursinondésdansplusieursdépartementsduSud-OuestmystèreMaisquiamassacrélesmagnoliasd’uneruedeColomiers\\xa0?TempoTempoFoodStyleBien-êtreEscapadeModeCardigan,béret,pullsansmanches,le«\\xa0Papycool\\xa0»estderetourFROMAGEFONDUCommentréussiràcoupsûrsaracletteraclettepartyTroisastucesdiététiquespoursefaireplaisiraveclaracletteHigh-TechHigh-TechSciencesEspaceJeuxvidéoRéseauxsociauxBytheWebAmazonGoogleMétaflippantTeslarappelledesvoiturespourunrisqueliéàlaconduiteassistéeABONNEMENTFindel’abonnement«\\xa0Essentiel\\xa0»,premièreoffresanspublicitédeNetflixVOTREVIE,VOTREAVISCommentferiez-voussansWhatsApp\\xa0?CequedisentnoslecteursVieProVieProFichesmétiersViedebureauReconversionprofessionnelleEntrepreneuriatEMPLOIBienpréparersonentretienannueld’évaluationMAILSCommentéduquerlesgensquicliquenttoutletempssur«\\xa0répondreàtous\\xa0»…ENTREPRENEURIATMicroentrepreneur,quelssontvosdroitsàlaretraite\\xa0?JO2024JO2024AthlétismeBMXEscrimeGymnastiqueJudoMarathonNatationSkateArgumentsLesJOcontrairesàlaluttepourleclimat\\xa0?AnneHidalgorépondATHLETISMEKevinMayerreporteàmarssatentativedequalificationolympiqueRécap'ZelenskyfaceauCongrèsaméricainau657ejourdelaguerreenUkraineVidéosVidéos20MinutesTVBriefTéléTikTechLechoixdeCaroCemomentoùPleinlesdoigtsLeDebriefOhMyFake03:17archéologieVasteprojetderénovationdesmursd’osdanslesCatacombesdeParis01:17podiumAmandinePellissarddansletopdespersonnalitéslesplustapéessurGoogl…03:00MEEEuhLebruitdesclochesdesvachesdérangecesSuissesPodcastsPodcastsMinutePapillon!SixièmescienceToutSexpliqueJusteundroitL'étédansvosoreillesEnImagesEnImagesGuided'achatGuided'achatBonsplansHightechMaisonLoisirsCodespromoLotoRésultatsLotoFDJ:quelssontlesnumérosgagnantsdecemercredi13décem…bonplan7appareilsindispensablesàvotrecuisineavantlesfêtesdefind'annéebonplanDécouvrezlesoffresdefind’annéeSamsungLedirectLedirectLes+lusLes+partagésLes+commentésJeuxJeuxLemotdujourMotsFléchésMotsCroisésSudokuSudokuKillerSudokuirrégulierSolitairePuzzleServicesServicesJournalnumériqueMinutesMaisonSportuneBébésetMamansJournaldesSeniorsCuisined'AnnieMesNoticesInfostraficActualitéRégionsSportDivertissementPlanèteTempoHigh-TechVieProJO2024VidéosPodcastsEnImagesGuided'achatLedirectJeuxServicesNewslettersJournalJeuxHoroscopeDansl’actuGuerreHamas-IsraëlGuerreenUkraineLedirectActualitéActualitéSociétéMondeFaitsdiversEconomieSantéPolitiqueJusticeFakeOffLesenquêtesde20MinutesRégionsRégionsParisMarseilleToulouseLilleNantesLyonBordeauxMontpellierNiceRennesStrasbourgSportSportFootballBiathlonTennisRugbyBasketHandballCyclismeFormule1MercatoLivescoreDivertissementDivertissementCultureT'asvu?PeopleWebTélévisionCinémaSérieLivresMédiasMusiquePlanètePlanèteÉcologieÉnergieAnimauxMétéoPlantesOcéansTempoTempoFoodStyleBien-êtreEscapadeHigh-TechHigh-TechSciencesEspaceJeuxvidéoRéseauxsociauxBytheWebAmazonGoogleMétaApple20MintVieProVieProFichesmétiersViedebureauReconversionprofessionnelleEntrepreneuriatJO2024JO2024AthlétismeBMXEscrimeGymnastiqueJudoMarathonNatationSkateParalympiquesVidéosVidéos20MinutesTVBriefTéléTikTechLechoixdeCaroCemomentoùPleinlesdoigtsLeDebriefOhMyFakeLeBriefÇadatepasd'hierAnimaux2.0ExplicagifPodcastsPodcastsMinutePapillon!SixièmescienceToutSexpliqueJusteundroitL'étédansvosoreillesEnImagesGuided'achatGuided'achatBonsplansHightechMaisonLoisirsCodespromoLedirectLedirectLes+lusLes+partagésLes+commentésJeuxJeuxLemotdujourMotsFléchésMotsCroisésSudokuSudokuKillerSudokuirrégulierSolitairePuzzleMotsCoupésAnagrammesMotsMélangésMotsCasésiFléchésMotscodésJeudes8différencesRondedesMotsTakuzuKemaruFubukiBuzzKakuroGaramMatoku421BatailleNavaleHashiCryptoCampingServicesServicesJournalnumériqueMinutesMaisonSportuneBébésetMamansJournaldesSeniorsCuisined'AnnieMesNoticesInfostraficConjugaisonHoroscopeInfolocaleHoroscopechinoisMagazineRetoursurlapaged'accueil20MinutesRecherchePrécédentSuivantRechercheLedirectLes+lus21H56•AUDIENCE«\\xa0T’asquoiàcacher\\xa0?\\xa0»Face-à-facetenduentreMoniqueOlivieretsonfils21H33•CapitalePourquoiBourgesest-elledésignéecapitaleeuropéennedelacultureen\\xa02028\\xa0?20H26•états-unisHunterBidendéfielesrépublicainsetdéfendsonpère20H17•RécapBidenrencontredesfamillesd’otagesaméricainsau68ejourduconflit20H09•DANGERQuelssontlesrisquespourlevillagedeMaurienneaprèsl’éboulementXXL\\xa0?1TAPISPOURTOUSSouriresetflashsautourdeMiladypour«\\xa0LesTroisMousquetaires\\xa0»2tractationsZelenskyrepartdeWashingtonlesmainspresquevides3ACCIDENTDELAROUTEIlsetueauvolantd’unePorsche,sonamiquilesuivaitprendlafuiteRetoursurlapaged'accueil20MinutesFacebookTwitterInstagramSnapchatTiktokYoutubeDailymotionFlipboardNosapplicationsDécouvrezl‘ensembledenosapplications20Minutes!TéléchargersurAppStoreTéléchargersurGooglePlayActualitésSociétéFaitsdiversPolitiqueMondeSantéJusticeFactCheckingLespluspartagésServicesDistributionHoroscopeConjugaisonCuisined'AnnieMinutesMaisonBébésetMamansJournaldesSeniorsSportuneMesnotices20MinutesRecrutement20MinutesMédiaPaneldesLecteurs20MinutesLivresChartecommentaireJeuxJeuxenligneMotsfléchésSolitaireMotscroisésPuzzleMotscoupésSudokuAnagrammesShoppingGuided'achatHighTechBonsplansLotoFDJSmartphonesSoldesBlackFridayFrenchDaysCodespromoCodepromogratuitCodepromoAliExpressCodepromoCarrefourCodepromoDellCodepromoVistaprintCodepromoSheinCodepromoSFRCodepromoUberEatsPlandusiteNotrecharteJournalPDFArchivesPublicitéMentionslégalesCGUProtectiondesdonnéespersonnellesGestiondescookiesSupprimerlescookiespublicitaireséditeurNouscontacterChoixdeconsentement©Copyright20MinutesLafréquentationde20Minutesestcertifiéeparl‘ACPM\""
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "response = requests.get(\"https://www.20minutes.fr/search?q=IA#gsc.tab=0&gsc.q=IA&gsc.page=1\").text\n",
        "soup = BeautifulSoup(response, \"html.parser\")\n",
        "text = soup.text.replace(\"\\n\", \" \").replace(\"\\t\", \" \").replace(' ', '')\n",
        "\n",
        "text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "s6r8bs5nqkKJ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PkkoeO0cqkGx"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dWPjaab-qkDp"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3yB04JoNqkAx"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6fwQVyZrqj9q"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qgBPuK8Zqj6i"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PXjvErobqj3r"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O_JYxqxAqj0q"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tb8Dwoxwqjxr"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SNcc_d0Tqjum"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vNEdw_ai6HaU"
      },
      "source": [
        "# **Fine-tuning**\n",
        "\n",
        "Le fine-tuning permet d'entraîner un large modèle de langue tels que GPT3.5 sur des données spécifiques.\n",
        "\n",
        "\n",
        "Le réglage fin améliore l'apprentissage en quelques étapes en s'entraînant sur beaucoup plus d'exemples que ne peut en contenir l'invite, vous permettant d'obtenir de meilleurs résultats sur un grand nombre de tâches. Une fois qu'un modèle a été affiné, vous n'aurez plus besoin de fournir autant d'exemples dans l'invite. Cela permet de réduire les coûts et de permettre des requêtes à faible latence.\n",
        "\n",
        "Le réglage fin vous permet de tirer le meilleur parti des modèles disponibles via l'API en fournissant :\n",
        "\n",
        "1. Des résultats de meilleure qualité que les invites\n",
        "2. Capacité à s'entraîner sur plus d'exemples que ne peut en contenir une invite\n",
        "3. Économies de jetons grâce à des invites plus courtes\n",
        "4. Demandes de latence réduites\n",
        "\n",
        "\n",
        "<img src='https://images.openai.com/blob/d8d965fd-e54c-4c9b-9d7d-b5d9910d38b2/gpt-3-5-turbo-fine-tuning-and-api-updates.png?trim=0,0,0,0&width=3200'>\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HZZLTFQU6NYV"
      },
      "source": [
        "**Les modèles supportés par le fine-tuning**\n",
        "\n",
        "Un réglage fin est actuellement disponible pour les modèles suivants :\n",
        "\n",
        "- `gpt-3.5-turbo-0613`(recommandé)\n",
        "- `babbage-002`\n",
        "- `davinci-002`\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZrnJPzeM6RMG"
      },
      "source": [
        "**Tarification**\n",
        "\n",
        "Les coûts de réglage fin sont répartis en deux catégories : le coût de formation initial et le coût d'utilisation :\n",
        "\n",
        "- Formation : 0,008 $ / 1 000 tokens\n",
        "\n",
        "- Entrée d'utilisation : 0,012 $ / 1 000 tokens\n",
        "\n",
        "- Sortie d'utilisation : 0,016 $ / 1 000 tokens\n",
        "\n",
        "Par exemple, un gpt-3.5-turbotravail de mise au point avec un fichier de formation de 100 000 jetons formés pendant 3 époques aurait un coût attendu de 2,40 $.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hXcIYce46TvY"
      },
      "source": [
        "**Cas d'utilisation courants**\n",
        "\n",
        "Quelques cas d'utilisation courants dans lesquels un réglage fin peut améliorer les résultats :\n",
        "\n",
        "- Définir le style, le ton, le format ou d'autres aspects qualitatifs\n",
        "- Améliorer la fiabilité pour produire le résultat souhaité\n",
        "- Correction des échecs de suivi d'invites complexes\n",
        "- Gérer de nombreux cas extrêmes de manière spécifique\n",
        "- Exécuter une nouvelle compétence ou une nouvelle tâche difficile à articuler dans une invite\n",
        "\n",
        "Une manière générale d'envisager ces cas consiste à considérer qu'il est plus facile de « montrer, pas de dire ». Dans les sections à venir, nous explorerons comment configurer les données pour un réglage fin et divers exemples dans lesquels le réglage fin améliore les performances par rapport au modèle de base."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "03tZTidi6WRn"
      },
      "source": [
        "**Méthodologie**\n",
        "\n",
        "Le réglage fin améliore l'apprentissage en quelques étapes en s'entraînant sur beaucoup plus d'exemples que ne peut en contenir l'invite, vous permettant d'obtenir de meilleurs résultats sur un grand nombre de tâches. Une fois qu'un modèle a été affiné, vous n'aurez plus besoin de fournir autant d'exemples dans l'invite. Cela permet de réduire les coûts et de permettre des requêtes à faible latence.\n",
        "\n",
        "À un niveau élevé, le réglage fin implique les étapes suivantes :\n",
        "\n",
        "1. Préparer et télécharger les données d'entraînement\n",
        "2. Former un nouveau modèle affiné\n",
        "3. Utilisez votre modèle affiné\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dZD1WxVU6Yt5"
      },
      "source": [
        "### **1. Préparer et télécharger les données d'entraînement**\n",
        "\n",
        "Le réglage fin nécessite un fichier de formation au format JSONL. Chaque ligne du fichier doit contenir un objet JSON avec les clés/valeurs suivantes :\n",
        "\n",
        "- Pour les modèles `ChatCompletion` gt3.5-turbo-0613 :\n",
        "\n",
        "```{\n",
        "    \"message\":[\n",
        "        {\n",
        "            \"role\":\"system\",\n",
        "            \"content\":\"contenu du message\"\n",
        "        },\n",
        "        {\n",
        "            \"role\":\"user\",\n",
        "            \"content\":\"contenu du message\"\n",
        "        },\n",
        "        {\n",
        "            \"role\":\"assistant\",\n",
        "            \"content\":\"contenu du message\"\n",
        "        }\n",
        "    ]\n",
        "}\n",
        "```\n",
        "\n",
        "- Pour les modèles `TextGeneration` :\n",
        "```\n",
        "{\"prompt\": \"<prompt text>\", \"completion\": \"<ideal generated text>\"}\n",
        "```\n",
        "\n",
        "`**Attention**` : **Chaque message doit être placé sur une ligne dans le fichier JSONL. Les messages peuvent être de n'importe quelle longueur.**\n",
        "\n",
        "**Au moins 10 messages sont nécessaires** pour entraîner un modèle. Pour obtenir de meilleurs résultats, nous recommandons d'utiliser au moins 100 messages. Pour les modèles de génération de texte, nous recommandons d'utiliser au moins 1000 messages.\n",
        "\n",
        "Le réglage fin est disponible à partir de la version 0.28.0 de l'[API d'OpenAI](https://platform.openai.com/docs/guides/fine-tuning)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "71dCavKG6H7a"
      },
      "outputs": [],
      "source": [
        "# Structure des données pour l'entrainement d'un modèle ChatCompletion\n",
        "# Moèle concerné : gpt-3.5-turbo-0613 :\n",
        "\n",
        "{\"messages\": [{\"role\": \"system\", \"content\": \"Marv is a factual chatbot that is also sarcastic.\"}, {\"role\": \"user\", \"content\": \"What is fine-tuning in machine learning?\"}, {\"role\": \"assistant\", \"content\": \"Fine-tuning in machine learning involves training a pre-existing model on a specific task or dataset to make it more accurate or suitable for that task. It's like giving the model specialized knowledge.\"}]}\n",
        "{\"messages\": [{\"role\": \"system\", \"content\": \"Marv is a factual chatbot that is also sarcastic.\"}, {\"role\": \"user\", \"content\": \"Why is fine-tuning important for AI models?\"}, {\"role\": \"assistant\", \"content\": \"Fine-tuning is crucial because it allows AI models to adapt to specific applications or domains, improving their performance and making them more useful in real-world scenarios.\"}]}\n",
        "{\"messages\": [{\"role\": \"system\", \"content\": \"Marv is a factual chatbot that is also sarcastic.\"}, {\"role\": \"user\", \"content\": \"Can you explain the steps involved in fine-tuning a language model?\"}, {\"role\": \"assistant\", \"content\": \"Certainly! Fine-tuning typically includes preparing training data, training the model on that data, and then using the fine-tuned model for your specific tasks. It's a process of specialization.\"}]}\n",
        "{\"messages\": [{\"role\": \"system\", \"content\": \"Marv is a factual chatbot that is also sarcastic.\"}, {\"role\": \"user\", \"content\": \"What models can be fine-tuned for language tasks?\"}, {\"role\": \"assistant\", \"content\": \"Currently, you can fine-tune models like gpt-3.5-turbo-0613, babbage-002, and davinci-002. These models can be adapted to various language-related tasks.\"}]}\n",
        "{\"messages\": [{\"role\": \"system\", \"content\": \"Marv is a factual chatbot that is also sarcastic.\"}, {\"role\": \"user\", \"content\": \"When should I consider using fine-tuning for AI models?\"}, {\"role\": \"assistant\", \"content\": \"You should consider fine-tuning when you need to tailor a model for specific tasks or improve its performance on certain applications. It's a powerful tool for customization.\"}]}\n",
        "{\"messages\": [{\"role\": \"system\", \"content\": \"Marv is a factual chatbot that is also sarcastic.\"}, {\"role\": \"user\", \"content\": \"How can fine-tuning benefit natural language processing (NLP) tasks?\"}, {\"role\": \"assistant\", \"content\": \"Fine-tuning can make NLP models more accurate and contextually aware for tasks like text generation, translation, sentiment analysis, and more. It's all about making the model 'smarter' in a particular domain.\"}]}\n",
        "{\"messages\": [{\"role\": \"system\", \"content\": \"Marv is a factual chatbot that is also sarcastic.\"}, {\"role\": \"user\", \"content\": \"What is the role of training data in fine-tuning?\"}, {\"role\": \"assistant\", \"content\": \"Training data is essential for fine-tuning as it helps the model learn from examples. You need a diverse set of conversations or text that reflects the scenarios you want the model to handle.\"}]}\n",
        "{\"messages\": [{\"role\": \"system\", \"content\": \"Marv is a factual chatbot that is also sarcastic.\"}, {\"role\": \"user\", \"content\": \"How many training examples should I provide for fine-tuning?\"}, {\"role\": \"assistant\", \"content\": \"You should provide at least 10 training examples, but for optimal results, it's often recommended to have between 50 and 100 examples. The right number depends on your specific use case.\"}]}\n",
        "{\"messages\": [{\"role\": \"system\", \"content\": \"Marv is a factual chatbot that is also sarcastic.\"}, {\"role\": \"user\", \"content\": \"What are the token limits for fine-tuning examples?\"}, {\"role\": \"assistant\", \"content\": \"Each fine-tuning example is limited to 4096 tokens. Make sure the total token count in the messages' content is under 4,000 to fit within this limit.\"}]}\n",
        "{\"messages\": [{\"role\": \"system\", \"content\": \"Marv is a factual chatbot that is also sarcastic.\"}, {\"role\": \"user\", \"content\": \"How can I estimate the costs of fine-tuning?\"}, {\"role\": \"assistant\", \"content\": \"You can estimate the costs by using this formula: base cost per 1,000 tokens * number of tokens in the input file * number of training epochs. This will give you an idea of the expected cost for your fine-tuning job.\"}]}\n",
        "\n",
        "\n",
        "# Structure des données pour l'entrainement d'un modèle Completion\n",
        "# Moèle concerné : babbage-002 et davinci-002\n",
        "\n",
        "{\"prompt\": \"<prompt text>\", \"completion\": \"<ideal generated text>\"}\n",
        "{\"prompt\": \"<prompt text>\", \"completion\": \"<ideal generated text>\"}\n",
        "{\"prompt\": \"<prompt text>\", \"completion\": \"<ideal generated text>\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RczmCk1P6jHP"
      },
      "source": [
        "### **2. Former un nouveau modèle affiné**\n",
        "\n",
        "Une fois les instructions de formation préparées et placées dans un fichier `data.jsonl`, vous pouvez commencer à former votre modèle affiné en préparant les données d'entrainement puis en lançant la formation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u1ViCFq-6jm6"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import openai\n",
        "\n",
        "\n",
        "# Préparation des données pour l'entrainement d'un modèle ChatCompletion\n",
        "openai.api_key = 'YOUR_API_KEY'\n",
        "response = openai.File.create(\n",
        "  file=open(\"./data.jsonl\", \"rb\"),\n",
        "  purpose='fine-tune'\n",
        ")\n",
        "response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tYfo6FOf6oGN"
      },
      "outputs": [],
      "source": [
        "# Entrainement du modèle ChatCompletion sur les serveurs d'OpenAI\n",
        "response_train_model = openai.FineTuningJob.create(\n",
        "    training_file=response['id'],\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    )\n",
        "\n",
        "response_train_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H754ewbi6p9f"
      },
      "outputs": [],
      "source": [
        "openai.FineTuningJob.list()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-54aZADz6mDC"
      },
      "source": [
        "### **3. Utilisez votre modèle affiné**\n",
        "\n",
        "Une fois que votre modèle est formé, vous pouvez l'utiliser pour générer des résultats en utilisant l'API comme vous le feriez avec n'importe quel autre modèle. Il est possible de visualiser la courbe d'apprentissage de votre modèle dans le tableau de bord de votre compte :\n",
        "https://platform.openai.com/finetune"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kTw9t3p76vfJ"
      },
      "outputs": [],
      "source": [
        "[model['id'] for model in openai.Model().list()[\"data\"]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QhgM41x66yIA"
      },
      "outputs": [],
      "source": [
        "# Utilisation du modèle fine-tuné\n",
        "reponse = openai.ChatCompletion.create(\n",
        "    model='ft:gpt-3.5-turbo-0613:dawan::81DNLWeI',\n",
        "    messages=[\n",
        "        {\"role\": \"system\",\"content\": \"Marv is a factual chatbot that is also sarcastic.\"},\n",
        "        {\"role\": \"user\",\n",
        "         \"content\":\"What is fine-tuning in machine learning?\"},\n",
        "    ],\n",
        ")\n",
        "\n",
        "reponse['choices'][0]['message'][\"content\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GlCEJmOv6712"
      },
      "source": [
        "___\n",
        "\n",
        "# Exercice\n",
        "\n",
        "1. A L'aide de ChatGPT, créez un fichier de données d'entrainement au format JSONL contenant au moins 10 messages puis placez le dans un fichier `data.jsonl` Entrainez ensuite un modèle de chatbot sur un domaine de votre choix.\n",
        "**Astuce** : Copiez le contenu de votre choix (exemple : une page internet) puis demandez à GhatGPT de générer le fichier de données d'entrainement au format JSONL.\n",
        "\n",
        "2. Créez une méthode `openai_chat_finetune()` qui prend en paramètre le nom du fichier de données d'entrainement et retourne le nom du modèle entrainé.\n",
        "\n",
        "### **Exemple de prompt à envoyer à ChatGPT**\n",
        "\n",
        "```\n",
        "\n",
        "A partir du document suivant crée-moi un fichier jsonl contentant des exemples d'échange entre un chatbot et un utilisateur qui sera utilisé pour le fine-tuning d'un model gpt3 pour répondre aux questions de développeurs qui souhaite comprendre comment fonctionne le finetuning. Le jsonl aura la forme suivante :\n",
        "\n",
        "{\"messages\": [{\"role\": \"system\", \"content\": \"definir le rol system\"}, {\"role\": \"user\", \"content\": \"question type posé par un utilisateur\"}, {\"role\": \"assistant\", \"content\": \"Réponse de l'assistant\"}]}\n",
        "\n",
        "\n",
        "Le modèle du fichier json doit avoir cette forme :\n",
        "{\"messages\": [{\"role\": \"system\", \"content\": \"Marv is a factual chatbot that is also sarcastic.\"}, {\"role\": \"user\", \"content\": \"What's the capital of France?\"}, {\"role\": \"assistant\", \"content\": \"Paris, as if everyone doesn't know that already.\"}]}\n",
        "{\"messages\": [{\"role\": \"system\", \"content\": \"Marv is a factual chatbot that is also sarcastic.\"}, {\"role\": \"user\", \"content\": \"Who wrote 'Romeo and Juliet'?\"}, {\"role\": \"assistant\", \"content\": \"Oh, just some guy named William Shakespeare. Ever heard of him?\"}]}\n",
        "{\"messages\": [{\"role\": \"system\", \"content\": \"Marv is a factual chatbot that is also sarcastic.\"}, {\"role\": \"user\", \"content\": \"How far is the Moon from Earth?\"}, {\"role\": \"assistant\", \"content\": \"Around 384,400 kilometers. Give or take a few, like that really matters.\"}]}\n",
        "\n",
        "\n",
        "Propose moi à nouveau 20 exemples d'intéraction entre un assistant et un utilisateur au sujet du finetuning en respectant le modèle donné.\n",
        "\n",
        "Voici la documentation à partir de laquelle tu dois créer les exemples : à compléter\n",
        "\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kaS7n6bl68GU"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
